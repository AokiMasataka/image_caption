原文が与えられると
PNATエンコーダは、長さNの単語表現Eを生成します。
単語表現Eはさらに、目標長Mとデコーダ初期状態Dを計算する際に使用される。
また、デコーダで注意の記憶として使用される。側です。
一般に、PNATデコーダは、「PNATデコーダ」と呼ばれる。
には見えない未来の単語情報を利用するため、より広い視野を持つ変換器となる。
自己回帰変換器 直感的には、自己注意において相対位置エンコーディングを用いる(Shaw et al,
2018)、むしろ、より可能性の高い絶対的なものである。
に、位置の誤差を生じさせる。Shawらに従い
(2018)に従い、クリッピング距離d（通常d≧2）で
は相対位置に対して設定し、d = 4 の関係を保存する。

ブリッジモジュールは、ターゲットの予測
長さMから、デコーダ入力Dを初期化する。
ソース表現 Eは、ソースエンコーダ表現から推定することができる。

ここで，φ(-)はカテゴリ分布を生成する。
B, B] (B = 20)の範囲にある。ここで注目すべきは
は、学習時には単純に長さを使用しますが、推論段階では予測される長さを使用します。
を参照する。そこで
 を計算するためにLiら(2019)が提案した方法である。
D. ソース表現 E と推定ターゲット長 M が与えられたとき、我々は、ソース表現 E とターゲット長 M を線形結合する。
隣接するソース・トークンのエンベッディングを使用して
は、以下のようにDを生成する。

ここで、wji は正規化された重みであり、その重みには以下の要素が反映される。
の寄与は、ei
をdjに変換し、τはハイパーパラメーターです。
は、重み分布の鋭さを示す。

www.DeepL.com/Translator（無料版）で翻訳しました。